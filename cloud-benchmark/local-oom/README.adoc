# Local OOM Reproduction

This directory is interested in recreating the conditions for having pods OOMKilled on the benchmark run locally.

## Running the benchmark

1. First create all the required azure resources by running the `./script/setup-azure-resources.sh`
2. Add AZURE environment variables to the `kubernetes/multi-node-auctionmark.yaml` file under ConfigMap > data:
    ```
    AZURE_TENANT_ID: ...
    AZURE_CLIENT_ID: ...
    AZURE_CLIENT_SECRET: ...
    AZURE_SUBSCRIPTION_ID: ...
    ```
3. Build the docker image by running `./script/build.sh`, you may need to pick the right architecture for the yourkit agent
4. If you're using minikube you may need to run
    ```shell
    minikube image load xtdb-local-oom-auctionmark:latest
    ```
5. Apply the kubernetes configuration files
    ```shell
    kubectl apply -f kubernetes/kafka.yaml
    kubectl apply -f kubernetes/multi-node-auctionmark.yaml
    ```

You can run `./scripts/clear-resources.sh` or `./scripts/minikube-clear-resources.sh` in between runs to clear down kubernetes resources and blob storage.

## Running grafana and prometheus

Run the following commands to start grafana and prometheus:

```shell
kubectl apply -f kubernetes/prometheus-grafana.yaml
```

This should start grafana available on localhost:3010

NB. There's currently an issue with prometheus scraping the auctionmark pods which I haven't found a solution to so no metrics are coming through currently.

## Troubleshooting

### com.azure.storage.blob.models.BlobStorageException

If you see an error with the following content:
```
If you are using a StorageSharedKeyCredential, and the server returned an error message that says 'Signature did not match', you can compare the string to sign with the one generated by the SDK. To log the string to sign, pass in the context key value pair 'Azure-Storage-Log-String-To-Sign': true to the appropriate method call.\nIf you are using a SAS token, and the server returned an error message that says 'Signature did not match', you can compare the string to sign with the one generated by the SDK. To log the string to sign, pass in the context key value pair 'Azure-Storage-Log-String-To-Sign': true to the appropriate generateSas method call.\nPlease remember to disable 'Azure-Storage-Log-String-To-Sign' before going to production as this string can potentially contain PII.\nStatus code 403, \"ï»¿<?xml version=\"1.0\" encoding=\"utf-8\"?><Error><Code>AuthorizationPermissionMismatch</Code><Message>This request is not authorized to perform this operation using this permission.\nRequestId:e5908b51-d01e-0046-5d59-29e9ca000000\nTime:2024-10-28T16:47:09.2851512Z</Message></Error>\"
```

Then this means the roles assigned to the service principal are not sufficient to access the blob storage. You can assign the `Storage Blob Data Contributor` role to the service principal by running the following command:

  ```
  az role assignment create --assignee $CLIENT_ID --role "Storage Blob Data Contributor" --scope "/subscriptions/$SUBSCRIPTION_ID"
  ```
Or even just a full contributor role:

  ```
  az role assignment create --assignee $CLIENT_ID --role "Contributor" --scope "/subscriptions/$SUBSCRIPTION_ID"
  ```

These should be assigned by the setup script but the nuances required to authorize the service principal are quite subtle and may need to be adjusted.